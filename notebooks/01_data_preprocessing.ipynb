{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d5b9c31",
   "metadata": {},
   "source": [
    "Preprocessing Notebook for Credit Card Fraud Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45479ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime, timedelta\n",
    "import joblib\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "Path('../data/processed').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ced7927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the raw data\n",
    "\n",
    "df = pd.read_csv('../data/raw/creditcard.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "139890dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare log1p transformation, normalize after splitting to avoid data leakage\n",
    "df['Amount_log1p'] = np.log1p(df['Amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f9f2f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 199,364 | Val: 42,721 | Test: 42,722\n"
     ]
    }
   ],
   "source": [
    "# Create stratified train/test split to preserve the fraud ratio in each split\n",
    "\n",
    "feature_cols = [f'V{i}' for i in range(1, 29)] + ['Amount_log1p']  # Use log1p, not normalized yet\n",
    "X = df[feature_cols]\n",
    "y = df['Class']\n",
    "\n",
    "# Split: 70% train, 30% temp (using raw features)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Split temp: 50/50 -> 15% val, 15% test\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "# NOW normalize: Fit scaler ONLY on training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_train_scaled['Amount_normalized'] = scaler.fit_transform(X_train[['Amount_log1p']])\n",
    "\n",
    "# Transform validation and test using the scaler fitted on training data\n",
    "X_val_scaled = X_val.copy()\n",
    "X_val_scaled['Amount_normalized'] = scaler.transform(X_val[['Amount_log1p']])\n",
    "\n",
    "X_test_scaled = X_test.copy()\n",
    "X_test_scaled['Amount_normalized'] = scaler.transform(X_test[['Amount_log1p']])\n",
    "\n",
    "# Drop Amount_log1p, keep only V1-V28 and Amount_normalized\n",
    "feature_cols_final = [f'V{i}' for i in range(1, 29)] + ['Amount_normalized']\n",
    "X_train_final = X_train_scaled[feature_cols_final]\n",
    "X_val_final = X_val_scaled[feature_cols_final]\n",
    "X_test_final = X_test_scaled[feature_cols_final]\n",
    "\n",
    "# Combine with labels and save\n",
    "train_df = pd.concat([X_train_final, y_train], axis=1)\n",
    "val_df = pd.concat([X_val_final, y_val], axis=1)\n",
    "test_df = pd.concat([X_test_final, y_test], axis=1)\n",
    "\n",
    "train_df.to_csv('../data/processed/train.csv', index=False)\n",
    "val_df.to_csv('../data/processed/val.csv', index=False)\n",
    "test_df.to_csv('../data/processed/test.csv', index=False)\n",
    "\n",
    "# Save scaler for inference pipeline (fitted on training data only)\n",
    "joblib.dump(scaler, '../data/processed/amount_scaler.pkl')\n",
    "\n",
    "print(f\"Train: {len(train_df):,} | Val: {len(val_df):,} | Test: {len(test_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "527d56a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic IDs created: 10,000 users, 5,000 devices\n"
     ]
    }
   ],
   "source": [
    "#generate synthetic streaming fields because the original data lacks user_id, device_id, etc. and these are needed for behavioral features\n",
    "\n",
    "np.random.seed(42)\n",
    "df_stream = df.copy()\n",
    "\n",
    "# Entity counts\n",
    "N_USERS = 10000\n",
    "N_DEVICES = 5000\n",
    "N_IPS = 3000\n",
    "N_MERCHANTS = 500\n",
    "\n",
    "# Legitimate transactions: spread across many users/devices\n",
    "legit_mask = df_stream['Class'] == 0\n",
    "df_stream.loc[legit_mask, 'user_id'] = np.random.randint(0, N_USERS, legit_mask.sum())\n",
    "df_stream.loc[legit_mask, 'device_id'] = np.random.randint(0, N_DEVICES, legit_mask.sum())\n",
    "df_stream.loc[legit_mask, 'ip_int'] = np.random.randint(0, N_IPS, legit_mask.sum())\n",
    "df_stream.loc[legit_mask, 'merchant_id'] = np.random.randint(0, N_MERCHANTS, legit_mask.sum())\n",
    "\n",
    "# Fraud: concentrated (500 users, 200 devices)\n",
    "fraud_mask = df_stream['Class'] == 1\n",
    "df_stream.loc[fraud_mask, 'user_id'] = np.random.randint(0, 500, fraud_mask.sum())\n",
    "df_stream.loc[fraud_mask, 'device_id'] = np.random.randint(0, 200, fraud_mask.sum())\n",
    "df_stream.loc[fraud_mask, 'ip_int'] = np.random.randint(0, N_IPS // 2, fraud_mask.sum())\n",
    "df_stream.loc[fraud_mask, 'merchant_id'] = np.random.randint(0, N_MERCHANTS, fraud_mask.sum())\n",
    "\n",
    "# Convert to string IDs\n",
    "df_stream['user_id'] = 'user_' + df_stream['user_id'].astype(int).astype(str)\n",
    "df_stream['device_id'] = 'dev_' + df_stream['device_id'].astype(int).astype(str)\n",
    "df_stream['ip'] = '192.168.' + (df_stream['ip_int'] // 256).astype(int).astype(str) + '.' + (df_stream['ip_int'] % 256).astype(int).astype(str)\n",
    "df_stream['merchant_id'] = 'merch_' + df_stream['merchant_id'].astype(int).astype(str)\n",
    "\n",
    "print(f\"Synthetic IDs created: {N_USERS:,} users, {N_DEVICES:,} devices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34b477f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamps: 2013-09-01T00:00:00Z to 2013-09-02T23:59:52Z\n"
     ]
    }
   ],
   "source": [
    "#Convert time to ISO Timestamps and add country/currency\n",
    "\n",
    "# Dataset is from September 2013, European cardholders\n",
    "start_time = datetime(2013, 9, 1, 0, 0, 0)  # Sept 1, 2013 (actual dataset period)\n",
    "\n",
    "df_stream['ts'] = df_stream['Time'].apply(\n",
    "    lambda x: (start_time + timedelta(seconds=x)).isoformat() + 'Z'\n",
    ")\n",
    "df_stream['event_id'] = 'evt_' + df_stream.index.astype(str)\n",
    "\n",
    "# European country distribution (European cardholders)\n",
    "df_stream['country'] = np.random.choice(\n",
    "    ['FR', 'DE', 'IT', 'ES', 'GB', 'NL', 'BE'], \n",
    "    size=len(df_stream), \n",
    "    p=[0.25, 0.20, 0.15, 0.15, 0.10, 0.10, 0.05]\n",
    ")\n",
    "\n",
    "# Currency mapping (mostly EUR)\n",
    "currency_map = {'FR': 'EUR', 'DE': 'EUR', 'IT': 'EUR', 'ES': 'EUR', 'GB': 'GBP', 'NL': 'EUR', 'BE': 'EUR'}\n",
    "df_stream['currency'] = df_stream['country'].map(currency_map)\n",
    "df_stream['amount'] = df_stream['Amount']\n",
    "\n",
    "print(f\"Timestamps: {df_stream['ts'].iloc[0]} to {df_stream['ts'].iloc[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3bc03e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: streaming_events.csv (284,807 events)\n",
      "Saved: streaming_events_sample.csv (10,000 events)\n"
     ]
    }
   ],
   "source": [
    "#Save Streaming Events\n",
    "\n",
    "stream_cols = [\n",
    "    'event_id', 'ts', 'user_id', 'amount', 'currency',\n",
    "    'country', 'device_id', 'ip', 'merchant_id', 'Class'\n",
    "]\n",
    "\n",
    "df_stream[stream_cols].to_csv('../data/processed/streaming_events.csv', index=False)\n",
    "df_stream[stream_cols].head(10000).to_csv('../data/processed/streaming_events_sample.csv', index=False)\n",
    "\n",
    "print(f\"Saved: streaming_events.csv ({len(df_stream):,} events)\")\n",
    "print(f\"Saved: streaming_events_sample.csv (10,000 events)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6601cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Metadata\n",
    "feature_cols_final = [f'V{i}' for i in range(1, 29)] + ['Amount_normalized']  # Use final feature list\n",
    "\n",
    "metadata = {\n",
    "    'dataset': {\n",
    "        'total_samples': len(df),\n",
    "        'fraud_samples': int(df['Class'].sum()),\n",
    "        'fraud_rate': float(df['Class'].mean()),\n",
    "    },\n",
    "    'splits': {\n",
    "        'train_size': len(train_df),\n",
    "        'val_size': len(val_df),\n",
    "        'test_size': len(test_df),\n",
    "    },\n",
    "    'features': {\n",
    "        'model_features': feature_cols_final,  # Use final feature list\n",
    "        'feature_count': len(feature_cols_final),\n",
    "    },\n",
    "    'preprocessing': {\n",
    "        'amount_transformation': 'log1p + StandardScaler',\n",
    "        'scaler_path': 'data/processed/amount_scaler.pkl',\n",
    "        'scaler_fit_data': 'training_set_only',  # Important note\n",
    "    },\n",
    "    'synthetic': {\n",
    "        'n_users': N_USERS,\n",
    "        'n_devices': N_DEVICES,\n",
    "        'n_ips': N_IPS,\n",
    "        'n_merchants': N_MERCHANTS,\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('../data/processed/preprocessing_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
